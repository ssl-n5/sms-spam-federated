{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qClkoh6qFmHm",
        "outputId": "6b50215e-1c14-4209-c399-9884848e779f"
      },
      "outputs": [],
      "source": [
        "colab = False #when used in Google Colab\n",
        "\n",
        "if colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "--TNTVvZ7fDN"
      },
      "source": [
        " <a id=\"1\"></a>\n",
        "# <p style=\"background-color:#E598D8;font-family:newtimeroman;color:#E1F16B;font-size:150%;text-align:center;border-radius:20px 60px;\">IMPORTING LIBRARIES</p>\n",
        "\n",
        "**Code primarily makes use of NLTK and SKLEARN libraries for preprocessing, training, and testing.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-05T06:55:46.003755Z",
          "iopub.status.busy": "2021-07-05T06:55:46.003119Z",
          "iopub.status.idle": "2021-07-05T06:55:47.734038Z",
          "shell.execute_reply": "2021-07-05T06:55:47.733267Z",
          "shell.execute_reply.started": "2021-07-05T06:55:46.003715Z"
        },
        "id": "9qWLByXk7fDN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Importing all the libraries to be used\n",
        "from python import Lem #importing python file for Filipino lemmatization\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "\n",
        "# nltk library for preprocessing and data cleaning\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#training, testing, and evaluation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_0qYmEXLbWd",
        "outputId": "4b2fbb09-1372-4fe6-8164-4b9d0b9d3b30"
      },
      "outputs": [],
      "source": [
        "#nltk files that cannot be found by Colab unless downloaded\n",
        "if colab:\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpXNshOIOiIy"
      },
      "outputs": [],
      "source": [
        "#IMPORT ALL DATA FILES FOR CLIENTS\n",
        "if colab: \n",
        "  directory = '/content/drive/MyDrive/Thesis/'\n",
        "\n",
        "y_train = pd.read_csv('train_labels.csv')\n",
        "X_train = np.load(directory + 'train_data.npy')\n",
        "y_test = pd.read_csv('test_labels.csv')\n",
        "X_test = np.load(directory + 'test_data.npy')\n",
        "\n",
        "labelset = [y_train, y_test]\n",
        "\n",
        "for count in range(len(labelset)):\n",
        "  series = labelset[count]\n",
        "  indx = series.index\n",
        "  index = [series.iloc[i, 0] for i in range(0,len(indx))]\n",
        "  vals = [series.iloc[i, 1] for i in range(0,len(indx))]\n",
        "  labelset[count]= pd.Series(vals, index)\n",
        "  #print(trainset[count])\n",
        "\n",
        "y_train, y_test = labelset[0], labelset[1]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VkFHQaGB7fDU"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "# <p style=\"background-color:#E598D8;font-family:newtimeroman;font-size:150%;color:#E1F16B;text-align:center;border-radius:20px 60px;\">MODEL BUILDING</p>\n",
        "\n",
        "**Steps involved in the Model Building**\n",
        "* Setting up features and target as X and y\n",
        "* Splitting the testing and training sets\n",
        "* Build a pipeline of model for four different classifiers.\n",
        "  1. Support Vector Machines\n",
        "* Fit all the models on training data\n",
        "* Get the cross-validation on the training set for all the models for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-05T06:56:03.957430Z",
          "iopub.status.busy": "2021-07-05T06:56:03.957147Z",
          "iopub.status.idle": "2021-07-05T06:57:05.191655Z",
          "shell.execute_reply": "2021-07-05T06:57:05.190756Z",
          "shell.execute_reply.started": "2021-07-05T06:56:03.957405Z"
        },
        "id": "L7Zmh6MP7fDV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Testing on the following classifiers\n",
        "classifiers = [SVC()]\n",
        "for cls in classifiers:\n",
        "    cls.fit(X_train, y_train)\n",
        "pipe_dict = {0: \"SVC\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-07-05T06:57:05.194052Z",
          "iopub.status.busy": "2021-07-05T06:57:05.193606Z",
          "iopub.status.idle": "2021-07-05T07:07:05.704340Z",
          "shell.execute_reply": "2021-07-05T07:07:05.702962Z",
          "shell.execute_reply.started": "2021-07-05T06:57:05.194021Z"
        },
        "id": "NxVal7HJ7fDV",
        "outputId": "8a00b9ca-ab8a-403e-ee8d-a054adbcafb9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Crossvalidation\n",
        "for i, model in enumerate(classifiers):\n",
        "    #cv_score = cross_val_score(model, X_train,y_train,scoring=\"accuracy\", cv=10)\n",
        "    cv_score = cross_val_score(model, X_train,y_train,scoring=\"accuracy\", cv=10)\n",
        "    print(\"%s: %f \" % (pipe_dict[i], cv_score.mean()))\n",
        "    print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w0tHr6_-7fDV"
      },
      "source": [
        "<a id=\"7\"></a>\n",
        "# <p style=\"background-color:#E598D8;font-family:newtimeroman;font-size:150%;color:#E1F16B;text-align:center;border-radius:20px 60px;\">EVALUATING MODELS</p>\n",
        "**Testing the models on Testset**\n",
        "* Accuracy Report\n",
        "* Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-05T07:07:05.706174Z",
          "iopub.status.busy": "2021-07-05T07:07:05.705782Z",
          "iopub.status.idle": "2021-07-05T07:14:19.340446Z",
          "shell.execute_reply": "2021-07-05T07:14:19.339300Z",
          "shell.execute_reply.started": "2021-07-05T07:07:05.706130Z"
        },
        "id": "HlX8uBwQ7fDV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "# creating lists of varios scores\n",
        "precision =[]\n",
        "recall =[]\n",
        "f1_score = []\n",
        "trainset_accuracy = []\n",
        "testset_accuracy = []\n",
        "\n",
        "for i in classifiers:\n",
        "    pred_train = i.predict(X_train)\n",
        "    pred_test = i.predict(X_test)\n",
        "    prec = metrics.precision_score(y_test, pred_test)\n",
        "    recal = metrics.recall_score(y_test, pred_test)\n",
        "    f1_s = metrics.f1_score(y_test, pred_test)\n",
        "    train_accuracy = model.score(X_train,y_train)\n",
        "    test_accuracy = model.score(X_test,y_test)\n",
        "\n",
        "    #Appending scores\n",
        "    precision.append(prec)\n",
        "    recall.append(recal)\n",
        "    f1_score.append(f1_s)\n",
        "    trainset_accuracy.append(train_accuracy)\n",
        "    testset_accuracy.append(test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-05T07:14:19.342605Z",
          "iopub.status.busy": "2021-07-05T07:14:19.342267Z",
          "iopub.status.idle": "2021-07-05T07:14:19.349452Z",
          "shell.execute_reply": "2021-07-05T07:14:19.348739Z",
          "shell.execute_reply.started": "2021-07-05T07:14:19.342548Z"
        },
        "id": "DELZzakX7fDV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# initialise data of lists.\n",
        "data = {'Precision':precision,\n",
        "'Recall':recall,\n",
        "'F1score':f1_score,\n",
        "'Accuracy on Testset':testset_accuracy,\n",
        "'Accuracy on Trainset':trainset_accuracy}\n",
        "# Creates pandas DataFrame.\n",
        "Results = pd.DataFrame(data, index =[\"SVC\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "execution": {
          "iopub.execute_input": "2021-07-05T07:14:19.351103Z",
          "iopub.status.busy": "2021-07-05T07:14:19.350629Z",
          "iopub.status.idle": "2021-07-05T07:14:19.422876Z",
          "shell.execute_reply": "2021-07-05T07:14:19.422054Z",
          "shell.execute_reply.started": "2021-07-05T07:14:19.351061Z"
        },
        "id": "mNNJzB817fDV",
        "outputId": "e2f100b8-2b97-4e0d-e81f-057cddfae606",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cmap2 = ListedColormap([\"#E2CCFF\",\"#E598D8\"])\n",
        "Results.style.background_gradient(cmap=cmap2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "execution": {
          "iopub.execute_input": "2021-07-05T07:14:19.424610Z",
          "iopub.status.busy": "2021-07-05T07:14:19.424105Z",
          "iopub.status.idle": "2021-07-05T07:14:38.830840Z",
          "shell.execute_reply": "2021-07-05T07:14:38.829640Z",
          "shell.execute_reply.started": "2021-07-05T07:14:19.424568Z"
        },
        "id": "DaAPOgs17fDV",
        "outputId": "31619643-ab63-49f7-9833-01bf3bd8cec5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cmap = ListedColormap([\"#E1F16B\", \"#E598D8\"])\n",
        "\n",
        "for cls in classifiers:\n",
        "    predictions = cls.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, predictions, labels=cls.classes_)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cls.classes_)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO7gyRu47fDW"
      },
      "outputs": [],
      "source": [
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename,'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "c9a898080901859fd54fd56ba22cd1dfeeb7caa0ea23f7a8225502b628e1b7b3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
